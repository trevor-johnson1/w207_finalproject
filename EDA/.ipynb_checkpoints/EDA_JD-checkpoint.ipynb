{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import data\n",
    "house_data =pd.read_csv('train.csv')\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions of Linear Regression\n",
    "\n",
    "Linear relationship\n",
    "Multivariate normality\n",
    "No or little multicollinearity\n",
    "No auto-correlation\n",
    "Homoscedasticity (Bresuh-Pagan)\n",
    "\n",
    "\n",
    "https://stats.stackexchange.com/questions/267513/assumptions-of-ridge-and-lasso-regression\n",
    "\n",
    "No assumption of normality for linear or Lasso/Regression.\n",
    "\n",
    "Homoscedasticity matters for all three, collinearity only for linear regression. We know collinearity is violated from DE no?\n",
    "\n",
    "https://www.statology.org/breusch-pagan-test-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take log transofmration - cut my earlier tests but take my word for it\n",
    "# we super failed Breush-Pagan\n",
    "\n",
    "house_data[\"GrLivArea\"] = np.log(house_data[\"GrLivArea\"])\n",
    "house_data[\"SalePrice\"] = np.log(house_data[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lagrange multiplier statistic', 14.187444038962928),\n",
       " ('p-value', 0.0008303012099263508),\n",
       " ('f-value', 7.148611996604519),\n",
       " ('f p-value', 0.0008138244469908738)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Breusch Pagan on log-transformed simple models\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# use robust standard errors, fit an ols model that Breusch-Pagan\n",
    "# is calculated from. Most of this found from documentation examples\n",
    "# online. Please note that unlike our accuracy checks, we need all \n",
    "# variables to be in the same dataframe to do this.\n",
    "fit = smf.ols('SalePrice ~ OverallQual + GrLivArea', data = house_data).fit(cov_type='HC3')\n",
    "# run for these four metrics, p-value is what we care about, below 0.05 means likely hetero\n",
    "# above 0.05 is our ultimate goal\n",
    "names = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(fit.resid, fit.model.exog)\n",
    "\n",
    "# used to print outputs cleanly ,feel free to copy.\n",
    "lzip(names, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d35cc5976a51>:26: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X_train, Y_train)\n",
      "C:\\Users\\19258\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\19258\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.749e+01, tolerance: 1.454e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 0.146 (0.012)\n",
      "Accuracy: 0.7355132218943015\n",
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.146 (0.012)\n",
      "Accuracy: 0.7355132218699294\n",
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.146 (0.012)\n",
      "Accuracy: 0.7356575783933235\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.146 (0.012)\n",
      "Accuracy: 0.7369003659433381\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.148 (0.012)\n",
      "Accuracy: 0.7421572867838987\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.186 (0.013)\n",
      "Accuracy: 0.6544391714540575\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.319 (0.026)\n",
      "Accuracy: -0.003263483235423026\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.319 (0.026)\n",
      "Accuracy: -0.003263483235423026\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.319 (0.026)\n",
      "Accuracy: -0.003263483235423026\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.319 (0.026)\n",
      "Accuracy: -0.003263483235423026\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/lasso-regression-with-python/\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# isolate our three variables\n",
    "X, Y = house_data[[\"GrLivArea\",\"OverallQual\"]], house_data[\"SalePrice\"]\n",
    "\n",
    "# I cut at 876 to split our data into 60% train, 40% test\n",
    "# for accuracy check\n",
    "X_train = X[:876]\n",
    "Y_train = Y[:876]\n",
    "X_test = X[877:]\n",
    "Y_test = Y[877:]\n",
    "\n",
    "# iterate over a smaple of alpha values\n",
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
    "    # define Lasso model\n",
    "    model = Lasso(alpha=i)\n",
    "    \n",
    "    # fit to our training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # 10-fold cross-validation for evaluating fit of training data\n",
    "    # for MAE calculation. see example in cite in top line\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # shamelessly copied form online, calculate the mean absolute error\n",
    "    scores = cross_val_score(model, X_train, Y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    \n",
    "    # calculate accuracy of lasso regression with built-in tools\n",
    "    print('Accuracy:', model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note Accuracy is optimized when MAE is not, sort of strange. Best results at alpha = 0.01. As alpha increase accuracy worsens until eventually going negative as mean absolute error spikes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
