{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices - Advanced Regression Techniques\n",
    "\n",
    "## Deva Kulkarni, Jared Dec, Marc Semonick, Trevor Johnson\n",
    "\n",
    "## October 2021\n",
    "\n",
    "<br>\n",
    "\n",
    "Competition Link: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "Goal: Predict sales price for each house (`SalePrice`). RMSE on log(pred) - log(actual) will be the evaluation metric. \n",
    "\n",
    "Inference Problem:  Given known variables about a house, accurately predict its sale price.\n",
    "\n",
    "Deliverable: Final submission dataset should contain only the two fields `ID` and `SalePrice`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import math\n",
    "import os \n",
    "\n",
    "# data manipulation/viz\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# modeling\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# linear modeling\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# tree modeling\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#K-Fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 80)\n",
      "(1460, 81)\n"
     ]
    }
   ],
   "source": [
    "# # optional directory set-up\n",
    "# working_dir = !pwd\n",
    "# train = pd.read_csv(os.path.join(working_dir[0], \"../../housing_data\", \"train.csv\"))\n",
    "# test = pd.read_csv(os.path.join(working_dir[0], \"../../housing_data\", \"test.csv\"))\n",
    "# sample = pd.read_csv(os.path.join(working_dir[0], \"../../housing_data\", \"sample_submission.csv\"))\n",
    "\n",
    "# Load data (Specific to Deva)\n",
    "test = pd.read_csv(\"../../housing_data/test.csv\")\n",
    "train = pd.read_csv(\"../../housing_data/train.csv\")\n",
    "sample = pd.read_csv(\"../../housing_data/sample_submission.csv\")\n",
    "print(test.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train =pd.read_csv('C:/Users/19258/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "# test = pd.read_csv(\"C:/Users/19258/Downloads/house-prices-advanced-regression-techniques/test.csv\")\n",
    "# sample = pd.read_csv(\"C:/Users/19258/Downloads/house-prices-advanced-regression-techniques/sample_submission.csv\")\n",
    "\n",
    "# print(\"train shape: {}\".format(train.shape))\n",
    "# print(\"test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count number of missing values per variable:\n",
      "LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType         8\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GarageYrBlt       81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64\n",
      "\n",
      "Number of missing values after running na_clean()\n",
      "Missing values in train: 0\n",
      "Missing values in test: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Count number of missing values per variable:\")\n",
    "print(train.isnull().sum()[train.isnull().sum() != 0])\n",
    "\n",
    "# function to clean the missing values\n",
    "def na_clean(df):\n",
    "    \n",
    "    # some vars are just too missing so I remove the field\n",
    "    df = df.drop(columns = [\"PoolQC\", \"MiscFeature\"])\n",
    "\n",
    "    # replace some numeric vars w/ median\n",
    "    median_replace_vars = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageArea']\n",
    "    for var in median_replace_vars:\n",
    "        df[var].fillna(df[var].median(), inplace = True)\n",
    "    \n",
    "    # replace some num vars w/ 0\n",
    "    zero_replace_vars = ['BsmtFullBath', 'BsmtHalfBath', 'GarageCars']\n",
    "    for var in zero_replace_vars:\n",
    "        df[var].fillna(0, inplace = True)\n",
    "    \n",
    "    # replace some cat vars w/ most freq value \n",
    "    df['MasVnrType'].fillna('None', inplace = True)\n",
    "    df['Electrical'].fillna('SBrkr', inplace = True)\n",
    "    df['MSZoning'].fillna('RL', inplace = True)\n",
    "    df['SaleType'].fillna('WD', inplace = True)\n",
    "    df['Utilities'].fillna('AllPub', inplace = True)\n",
    "    df['KitchenQual'].fillna('TA', inplace = True)\n",
    "    df['Functional'].fillna('Typ', inplace = True)\n",
    "\n",
    "    # other cat vars just put missing if there isn't a glaring most popular category\n",
    "    replace_missing_vars = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'Fence', 'Exterior1st', \n",
    "        'Exterior2nd', 'FireplaceQu']\n",
    "    for var in replace_missing_vars:\n",
    "        df[var].fillna(\"Missing\", inplace = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = na_clean(train)\n",
    "test = na_clean(test)\n",
    "\n",
    "# make sure there are no more missing values\n",
    "print(\"\\nNumber of missing values after running na_clean()\")\n",
    "print(\"Missing values in train: {}\".format(train.isnull().sum().sum()))\n",
    "print(\"Missing values in test: {}\".format(test.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Simplifying the data for any future model we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep adapting this formula to change how we feature engineer\n",
    "def feature_eng(df, test_data = False):\n",
    "    '''Input either the training or test data. \n",
    "    2nd arg set to True if it's the testing data. That way we ignore the final log transformation on sale price'''\n",
    "\n",
    "    # num features to just binarize b/c few houses have the feature\n",
    "    df[\"SwimmingPool\"] = df['PoolArea'].map(lambda x: 0 if x==0 else 1)\n",
    "    df[\"3SsnPorch\"] = df['3SsnPorch'].map(lambda x: 0 if x==0 else 1)\n",
    "    df[\"ScreenPorch\"] = df['ScreenPorch'].map(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "    # re-factoring vars:\n",
    "    # group the irregularities into 2 factor levels\n",
    "    df['LotShape'] = df['LotShape'].map({'Reg': 'Reg', 'IR1': 'Reg', 'IR2': 'Irreg', 'IR3': 'Irreg'})\n",
    "\n",
    "    # simplifying MSSubClass because we have the year built in another feature\n",
    "    df['MSSubClass'] = df['MSSubClass'].map(lambda x: \n",
    "        \"1_story\"   if (x in (20, 30, 40, 120)) else(\n",
    "        \"1.5_story\" if (x in (45, 50, 150)) else(\n",
    "        \"2_story\"   if (x in (60, 70, 75, 160, 180, 190)) else(\n",
    "        \"split\"     if (x in (80, 85)) else(\n",
    "        \"duplex\"    if (x ==90) else(\n",
    "        \"other\"))))))\n",
    "    df['MSSubClass'] = df['MSSubClass'].astype(\"object\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # deciding to drop a few features for various reasons\n",
    "    vars_to_drop = [\n",
    "        \"LowQualFinSF\", # hardly any variation\n",
    "        \"LandSlope\", # not much variation\n",
    "        \"PoolArea\", # binarized above\n",
    "        \"MiscVal\", # not much variation\n",
    "        \"Utilities\", # only 1 obs in training data different from regular\n",
    "        #\"KitchenAbvGr\" # hardly any variation. But, Deva included in lm's so including it now.\n",
    "        ]\n",
    "    df.drop(columns=vars_to_drop, inplace=True) \n",
    "\n",
    "    # adding a remodeled feature\n",
    "    df['Remodeled'] = (df.YearRemodAdd-df.YearBuilt) == 0\n",
    "\n",
    "    # total inside area will be a sum of 1st and 2nd floor sq ft\n",
    "    df['Total_Inside_Area'] = df['1stFlrSF'] + df['2ndFlrSF']\n",
    "    df.drop(columns = ['1stFlrSF', '2ndFlrSF', 'GrLivArea'], inplace = True)\n",
    "\n",
    "    # simplify the bathrooms variable\n",
    "    df['Bathrooms'] = df.BsmtFullBath + 0.5*df.BsmtHalfBath + df.FullBath + 0.5*df.HalfBath\n",
    "    df.drop(columns = ['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], inplace = True)\n",
    "\n",
    "    ### JARED EDITS\n",
    "    # minimal transformations.\n",
    "    \n",
    "    # for some vars values are 0, since ln(0) = -inf, I have to recode values of 0 to 1\n",
    "    # as ln(1) =0. \n",
    "    \n",
    "    #for x in range(len(df.BsmtFinSF1)):\n",
    "    #    if df['BsmtFinSF1'][x] ==0:\n",
    "    #        df['BsmtFinSF1'][x] = 1\n",
    "        \n",
    "    #for x in range(len(df.MasVnrArea)):\n",
    "    #    if df['MasVnrArea'][x] ==0:\n",
    "    #        df['MasVnrArea'][x] = 1\n",
    "    \n",
    "    #for x in range(len(df.GarageArea)):\n",
    "    #    if df['GarageArea'][x] ==0:\n",
    "    #        df['GarageArea'][x] = 1\n",
    "    \n",
    "    for x in range(len(df.TotalBsmtSF)):\n",
    "        if df['TotalBsmtSF'][x] ==0:\n",
    "            df['TotalBsmtSF'][x] = 1\n",
    "            \n",
    "    #for x in range(len(df.WoodDeckSF)):\n",
    "    #    if df['WoodDeckSF'][x] ==0:\n",
    "    #        df['WoodDeckSF'][x] = 1\n",
    "    \n",
    "    df.Total_Inside_Area = np.log(df.Total_Inside_Area)\n",
    "    df.TotalBsmtSF = np.log(df.TotalBsmtSF)\n",
    "    #df.GarageArea = np.log(df.GarageArea)  \n",
    "    #df.BsmtFinSF1 = np.log(df.BsmtFinSF1)\n",
    "    df.LotArea = np.log(df.LotArea)\n",
    "    #df.WoodDeckSF = np.log(df.WoodDeckSF)\n",
    "    #df.MasVnrArea = np.log(df.MasVnrArea)\n",
    "\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    # get log of sale price which will be our actual response variable\n",
    "    if test_data:\n",
    "        pass \n",
    "    else:\n",
    "        df['LogSalePrice'] = np.log(df.SalePrice)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6a284f422525>:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TotalBsmtSF'][x] = 1\n",
      "<ipython-input-5-6a284f422525>:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TotalBsmtSF'][x] = 1\n"
     ]
    }
   ],
   "source": [
    "# run function on test and train\n",
    "train = feature_eng(train)\n",
    "test = feature_eng(test, test_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to prep data for a very baseline linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_df_clean(df):\n",
    "\n",
    "    lm_vars = ['LotArea', 'Street', 'Neighborhood', 'OverallQual', 'OverallCond', 'YearRemodAdd', \n",
    "              'BsmtCond', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'YrSold', \n",
    "              'MoSold', 'Remodeled', 'Total_Inside_Area', 'Bathrooms']\n",
    "\n",
    "    df = pd.get_dummies(df[lm_vars], \n",
    "        columns = ['Street', 'Neighborhood', 'OverallQual', 'OverallCond', 'BsmtCond','KitchenQual'], \n",
    "        drop_first=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train/test data all ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = lm_df_clean(train)\n",
    "X_test = lm_df_clean(test)\n",
    "Y_train = train.SalePrice\n",
    "Y_test = sample.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline linear model is very overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on training data: 0.855\n",
      "Fit on testing data: -17.670\n"
     ]
    }
   ],
   "source": [
    "# Decent R2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_1 = LinearRegression(fit_intercept=True)\n",
    "lr_1.fit(X_train,Y_train)\n",
    "\n",
    "print(\"Fit on training data: {:.3f}\".format(lr_1.score(X_train,Y_train)))\n",
    "print(\"Fit on testing data: {:.3f}\".format(lr_1.score(X_test ,Y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same feature set with a baseline RandomForest is also overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on training data: 1.000\n",
      "Fit on testing data: -18.893\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state = 0)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Fit on training data: {:.3f}\".format(dt.score(X_train,Y_train)))\n",
    "print(\"Fit on testing data: {:.3f}\".format(dt.score(X_test ,Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic linear model with single coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on training data: 0.626\n",
      "Fit on testing data: -14.882\n"
     ]
    }
   ],
   "source": [
    "#Simplest possible model - Chose variable with highest coefficient from initial correlation matrix\n",
    "\n",
    "X_train_2 = train.drop(train.columns.difference(['OverallQual']), 1)\n",
    "X_test_2 = test.drop(test.columns.difference(['OverallQual']), 1)\n",
    "Y_train = train.SalePrice\n",
    "Y_test = sample.SalePrice\n",
    "\n",
    "lr_2 = LinearRegression(fit_intercept=True)\n",
    "lr_2.fit(X_train_2,Y_train)\n",
    "\n",
    "print(\"Fit on training data: {:.3f}\".format(lr_2.score(X_train_2,Y_train)))\n",
    "print(\"Fit on testing data: {:.3f}\".format(lr_2.score(X_test_2 ,Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "train_dummies = pd.get_dummies(train)\n",
    "\n",
    "# create the train and test splits\n",
    "dev_train, dev_test = train_test_split(train_dummies, test_size=0.3, random_state=1)\n",
    "\n",
    "# specify model\n",
    "rf = RandomForestRegressor(bootstrap=True, max_features='auto')\n",
    "\n",
    "# run grid search on range of values\n",
    "grid = {\n",
    "    \"n_estimators\": np.arange(100, 1001, 100),\n",
    "    'max_depth': np.arange(10, 101, 5),\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "}\n",
    "\n",
    "# put our parameters into GridSearch\n",
    "gscv = GridSearchCV(\n",
    "    estimator = rf, \n",
    "    param_grid = grid, \n",
    "    n_jobs = -1, \n",
    "    cv = 3)\n",
    "\n",
    "# run the search:\n",
    "# this took 26 min to run. \n",
    "# re-run if you want\n",
    "#results = gscv.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
    "\n",
    "# check out the best parameters\n",
    "#print(results.best_params_)\n",
    "# {'max_depth': 25, 'min_samples_split': 2, 'n_estimators': 900}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in dev_train:\n",
    "    for x in dev_train[i]:\n",
    "        if x ==np.inf:\n",
    "            print(i)\n",
    "        elif x ==-np.inf:\n",
    "            print(i)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.1005\n",
      "RMSE: 0.1545\n"
     ]
    }
   ],
   "source": [
    "# finally, run model on best parameters\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators = 900,\n",
    "    max_depth = 25,\n",
    "    max_features = 'auto',\n",
    "    min_samples_split = 2,  \n",
    "    bootstrap = True, \n",
    "    )\n",
    "\n",
    "# fit the model\n",
    "rf_reg.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
    "\n",
    "# evaluate it's performance on the unforseen testing set\n",
    "yhat = rf_reg.predict(dev_test.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']))\n",
    "resids = yhat - dev_test.LogSalePrice\n",
    "\n",
    "# evaluate rmse and mae on the testing data\n",
    "print(\"MAE: \" + str(round(np.mean(resids.apply(lambda x: math.fabs(x))),4)))\n",
    "print(\"RMSE: \" + str(round(np.mean(resids**2)**.5,4)))\n",
    "# MAE: 0.0999\n",
    "# RMSE: 0.154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on train: 0.981\n",
      "Score on test: 0.874\n"
     ]
    }
   ],
   "source": [
    "# score on train\n",
    "rf_train_score = rf_reg.score(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
    "print(\"Score on train: {:.3f}\".format(rf_train_score))\n",
    "\n",
    "# score on test/dev\n",
    "rf_dev_score = rf_reg.score(dev_test.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_test.LogSalePrice)\n",
    "print(\"Score on test: {:.3f}\".format(rf_dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variable importance plot\n",
    "var_imp = pd.DataFrame({\n",
    "    'feature': dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']).columns,\n",
    "    'importance': rf_reg.feature_importances_\n",
    "})\n",
    "var_imp.sort_values(\"importance\", ascending=False, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 7))\n",
    "topn = 20\n",
    "ax.barh(var_imp.head(topn).feature, var_imp.head(topn).importance)\n",
    "ax.set_ylabel(\"Importance\")\n",
    "ax.set_xlabel(\"Feature\")\n",
    "ax.set_title(\"Feature Importance Plot: Top {}\".format(topn))\n",
    "ax.invert_yaxis()\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-6bab5841d68a>:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.628430460973907, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 0.087 (0.012)\n",
      "Accuracy: 0.9096173100577971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6284312063829933, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.087 (0.012)\n",
      "Accuracy: 0.9096185787818667\n",
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.081 (0.012)\n",
      "Accuracy: 0.9132507746324088\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.083 (0.009)\n",
      "Accuracy: 0.8940152758144915\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.105 (0.013)\n",
      "Accuracy: 0.859686813280689\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.145 (0.018)\n",
      "Accuracy: 0.7585573083185597\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.165 (0.018)\n",
      "Accuracy: 0.6973420545079846\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.169 (0.018)\n",
      "Accuracy: 0.6766069116916817\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.186 (0.018)\n",
      "Accuracy: 0.6123765128478742\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.5164024107287357\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
    "\n",
    "    # iterate over every vbalkue of alpha in the list, fit lasso regression\n",
    "    model = Lasso(alpha = i)\n",
    "\n",
    "    # copying Trevor's code, delete certain variables that don't matter\n",
    "    model.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
    "\n",
    "    # run 10-fold Cross validation to improve fit\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # calculate scores\n",
    "    scores = cross_val_score(model, dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "\n",
    "    # calculate MAE, accuracy.\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    print('Accuracy:', model.score(dev_test.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_test.LogSalePrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/whats-the-difference-between-linear-regression-lasso-ridge-and-elasticnet-8f997c60cf29\n",
    "\n",
    "# set asige log_sale_price in separate vectors\n",
    "train_log_saleprice = dev_train.LogSalePrice\n",
    "test_log_saleprice = dev_test.LogSalePrice\n",
    "\n",
    "# drop unused variables\n",
    "dev_train2 = dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id'])\n",
    "dev_test2 = dev_test.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id'])\n",
    "\n",
    "# standardize all values of all variables in data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(dev_train2)\n",
    "dev_train2 = scaler.transform(dev_train2)\n",
    "\n",
    "scaler.fit(dev_test2)\n",
    "dev_test2 = scaler.transform(dev_test2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-fb793dd6367c>:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(dev_train2, train_log_saleprice)\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.62843046097393, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 24.030 (26.219)\n",
      "Accuracy: 0.8981174959371588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.628241031843313, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.087 (0.012)\n",
      "Accuracy: 0.8981175307683255\n",
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.085 (0.012)\n",
      "Accuracy: 0.8992488682595974\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.080 (0.012)\n",
      "Accuracy: 0.9014169827535079\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.084 (0.011)\n",
      "Accuracy: 0.889696285766076\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.158 (0.018)\n",
      "Accuracy: 0.6678616908099565\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
    "    \n",
    "    # run and fit lasso regression again, this time with completely standardized data\n",
    "    model = Lasso(alpha = i)\n",
    "\n",
    "    model.fit(dev_train2, train_log_saleprice)\n",
    "\n",
    "    # 10-fold cross validation to improve fit\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # calculate scores and accuracy\n",
    "    scores = cross_val_score(model, dev_train2, train_log_saleprice, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    print('Accuracy:', model.score(dev_test2, test_log_saleprice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -1.4809944462331912e+28\n",
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8984100668889496\n",
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8984276897756973\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8984276907803807\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8984276930926756\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8984270152404311\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8984134841231296\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8983854875570967\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8983236345273472\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8978958397338077\n",
      "Lasso alpha is equal to:  25.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8969458125703147\n",
      "Lasso alpha is equal to:  50.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8951943358745872\n",
      "Lasso alpha is equal to:  75.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.893512758573598\n",
      "Lasso alpha is equal to:  100.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8919607360093981\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 25.0, 50.0, 75.0, 100.0]:\n",
    "\n",
    "    # calculate ridge regression with completely standardized data\n",
    "    model2 = Ridge(alpha = i)\n",
    "\n",
    "    model2.fit(dev_train2, train_log_saleprice)\n",
    "\n",
    "    # run 10-fold cross validation\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # calculate score\n",
    "    scores = cross_val_score(model, dev_train2, train_log_saleprice, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "\n",
    "    # calculate MAE and Accuracy\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    print('Accuracy:', model2.score(dev_test2, test_log_saleprice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-81db0400b488>:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model3.fit(dev_train2, train_log_saleprice)\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.62843046097393, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8981174959371588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.628335746547939, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8981175134471356\n",
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8988660242652673\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.9005764254724125\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.8988497598118551\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.7821686812762276\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: 0.16684267192996027\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.301 (0.023)\n",
      "Accuracy: -0.004336028268388636\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
    "\n",
    "    # calculate Elastic Net with completely standardized data\n",
    "    model3 = ElasticNet(alpha = i)\n",
    "\n",
    "    model3.fit(dev_train2, train_log_saleprice)\n",
    "\n",
    "    # 10-fold cross-validation to improve fit\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # calculate scores, MAE, and accuracy\n",
    "    scores = cross_val_score(model, dev_train2, train_log_saleprice, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    print('Accuracy:', model3.score(dev_test2, test_log_saleprice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: -2.9220098658969695e+20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.72118e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9090398440397601\n",
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9090395456787759\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9090363058645661\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9089937861552309\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9081407277572608\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9049267782497724\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9027569601837326\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.900250933441873\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.8932291341481591\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
    "\n",
    "    # Ridge Regression with minimally transofrmed data\n",
    "    model4 = Ridge(alpha = i)\n",
    "\n",
    "    model4.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
    "\n",
    "    # 10-fold cross-validation\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # calculate scores, MAE, and Accuracy\n",
    "    scores = cross_val_score(model, dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    print('Accuracy:', model4.score(dev_test.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_test.LogSalePrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-d0ab544ac6d7>:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model5.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.628430460973907, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9096173100577971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6284309765749048, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  1e-10\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9096179982275611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drkul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.168810520823647, tolerance: 0.01497720138328087\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso alpha is equal to:  0.0001\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9115223192844704\n",
      "Lasso alpha is equal to:  0.001\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.9001466273387907\n",
      "Lasso alpha is equal to:  0.01\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.8747716984359675\n",
      "Lasso alpha is equal to:  0.1\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.8124931358884635\n",
      "Lasso alpha is equal to:  0.5\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.708817847600673\n",
      "Lasso alpha is equal to:  1.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.6972995591240215\n",
      "Lasso alpha is equal to:  2.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.6765190484220713\n",
      "Lasso alpha is equal to:  10.0\n",
      "Mean MAE: 0.209 (0.020)\n",
      "Accuracy: 0.56552664890656\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
    "\n",
    "    # calculate elastic net with minimally transformed data\n",
    "    model5 = ElasticNet(alpha = i)\n",
    "\n",
    "    model5.fit(dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice)\n",
    "\n",
    "    # run 10-fold cross-validation\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # calculate scores, MAE, and accuracy\n",
    "    scores = cross_val_score(model, dev_train.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_train.LogSalePrice, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "    scores = absolute(scores)\n",
    "\n",
    "    print(\"Lasso alpha is equal to: \", i)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "    print('Accuracy:', model5.score(dev_test.drop(columns = [\"SalePrice\", 'LogSalePrice', 'Id']), dev_test.LogSalePrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deva Neural network attempt\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9a763963a0c2e3eb3033a1766c128288cb698df5642a2fe22798efe2c630a93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
